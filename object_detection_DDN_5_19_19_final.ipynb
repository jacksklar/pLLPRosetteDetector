{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection_DDN-5-19-19_final",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacksklar/pLLPRosetteDetector/blob/master/object_detection_DDN_5_19_19_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V8-yl-s-WKMG"
      },
      "source": [
        "# Neuromast Detector\n",
        "\n",
        "This model uses tensorflow and the MobileNet v1 CNN to detect epthelial protoneuromasts in two color 2D images of the zebrafish lateral line primordium "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Var-VjtvlZO",
        "colab_type": "text"
      },
      "source": [
        "#Install packages and and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpWZWSlSxXla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install tensorflow\n",
        "#!pip install tensorflow-gpu\n",
        "%%capture \n",
        "\n",
        "#clone the object detection models from github\n",
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "312jxvSsx6tQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install packages\n",
        "%%capture \n",
        "\n",
        "!sudo apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install --user Cython\n",
        "!pip install --user contextlib2\n",
        "!pip install --user jupyter\n",
        "!pip install 'prompt-toolkit==1.0.15'\n",
        "\n",
        "#need to restart runtime to use this downgraded version of prompt-tookit."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5izKRMWryMvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "import os\n",
        "os.chdir('/content/models/research/')\n",
        "#compile protobuf\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "#run the setup script to set up the object detection environment\n",
        "os.getcwd()\n",
        "!python3.6 setup.py build"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hV4P5gyTWKMI",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import re\n",
        "import ntpath\n",
        "from google.colab import drive\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
        "  raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n",
        "\n",
        "  \n",
        "#add libraries to python path\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\n",
        "\n",
        "#display matplotlib inline\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_6kOQT5FTLJ",
        "colab_type": "text"
      },
      "source": [
        "#clone the github repo\n",
        "Importing the labelled data from github for training, and the data to use as a test case after training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM9ZlQazYSDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#clone the repo including the data files and the py files into the models folder\n",
        "\n",
        "os.chdir(\"/content/models/research/\")\n",
        "\n",
        "#(remove the current cloned directory if there is one)\n",
        "!rm -r pLLPRosetteDetector \n",
        "\n",
        "!git clone https://github.com/jacksklar/pLLPRosetteDetector\n",
        "  \n",
        "#move the data directory from the cloned repo into the models directory\n",
        "!mv /content/models/research/pLLPRosetteDetector/data /content/models/research/data/\n",
        "\n",
        "#copy generate_tf_record py to the models folder\n",
        "!cp /content/models/research/pLLPRosetteDetector/generate_tfrecord.py /content/models/research/generate_tfrecord.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEB8JidhP6ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make the tf record using the modified generate_tf_record.py script\n",
        "\n",
        "!python generate_tfrecord.py --csv_input=/content/models/research/data/train_labels.csv  --output_path=/content/models/research/train.record\n",
        "!python generate_tfrecord.py --csv_input=/content/models/research/data/test_labels.csv  --output_path=/content/models/research/test.record"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dA0BgAc7F3J",
        "colab_type": "text"
      },
      "source": [
        "#Setting up to train the pre-existing model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rl40Zyk7Jtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "#make a folder to put the record files in under the research folder and move the record files there\n",
        "os.chdir(\"/content/models/research/\")\n",
        "!mkdir rosette_detect\n",
        "!mv train.record test.record rosette_detect\n",
        "\n",
        "#Grab the ssd_movilenet_v1 model\n",
        "!wget \"http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz\"\n",
        "\n",
        "#unzip the files from the model\n",
        "!tar -xvf ssd_mobilenet_v1_coco_2018_01_28.tar.gz\n",
        "\n",
        "#copy all the model files into the rosette_detect folder\n",
        "!cp /content/models/research/ssd_mobilenet_v1_coco_2018_01_28/model.ckpt.* rosette_detect\n",
        "\n",
        "#get the appropriate config file for the model we're using, in this case the edited version from the cloned github repo, and copy it to this directory\n",
        "!cp /content/models/research/pLLPRosetteDetector/ssd_mobilenet_v1_coco.config /content/models/research/rosette_detect\n",
        "\n",
        "os.chdir(\"/content/models/research/rosette_detect\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv4349Snx2Hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make the label map file\n",
        "\n",
        "%%writefile labelmap.pbtxt \n",
        "\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'nm'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm8FVzuIyu-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MO6lCUF4_xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up the model params\n",
        "\n",
        "\n",
        "#path to save the model outputs in\n",
        "model_dir = '/content/models/research/rosette_detect/training/'\n",
        "\n",
        "# remove content in output model directory if there is preexisting model runs and make a new directory.\n",
        "#!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9JBSuqNdUpz",
        "colab_type": "text"
      },
      "source": [
        "Can skip the next steps if we have a pre-frozen inference graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMG8KG-KG9nL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train the model. We're using 100,000 steps here for trainin\n",
        "\n",
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path='/content/models/research/rosette_detect/ssd_mobilenet_v1_coco.config' \\\n",
        "    --model_dir='/content/models/research/rosette_detect/training/' \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps=100000 \\\n",
        "    --num_eval_steps=5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VzlPNLuC7Vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the training files\n",
        "\n",
        "os.chdir(\"/content/models/research/rosette_detect/training\")\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DQceAg_OyWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export the trained inference graph\n",
        "\n",
        "\n",
        "os.chdir(\"/content/models/research/rosette_detect/training\")\n",
        "\n",
        "output_directory = '/content/models/research/rosette_detect/'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path='/content/models/research/rosette_detect/ssd_mobilenet_v1_coco.config' \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN0aS5DpODXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fozen inference graph should now be in here\n",
        "\n",
        "!ls /content/models/research/rosette_detect/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34_xEnUmRs92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download the trained file if you want to\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.download(pb_fname)\n",
        "files.download(label_map_pbtxt_fname)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekZr8As8dbp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#or, download the inference graph from githib, pretrained on 100,000 steps\n",
        "\n",
        "os.chdir('/content/models/research/rosette_detect/')\n",
        "\n",
        "!wget 'https://github.com/jacksklar/pLLPRosetteDetector/blob/master/frozen_inference_graph.pb'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr7wK1j1r5g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/gdrive/My Drive/final_test\")\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9YmRjO4R6LL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#inference test on final image folder from google drive\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "output_directory = '/content/models/research/rosette_detect/'\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "label_map_pbtxt_fname = '/content/models/research/rosette_detect/labelmap.pbtxt'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = '/content/models/research/rosette_detect/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "#PATH_TO_TEST_IMAGES_DIR =  \"/content/models/research/pLLPRosetteDetector/test\"\n",
        "PATH_TO_TEST_IMAGES_DIR =  \"/content/gdrive/My Drive/final_test\"\n",
        "\n",
        "\n",
        "#assert os.path.isfile(pb_fname)\n",
        "#assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrSXJEjrTMZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "num_classes = 1\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "    \n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    \n",
        "    #lets look at the output dict to see whats going wrong\n",
        "    #print(image_path)\n",
        "    #print(output_dict)\n",
        "    \n",
        "    #save the output dict to a file as csv format\n",
        "    \n",
        "    \n",
        "    \n",
        "    my_filename = ntpath.basename(image_path)\n",
        "    my_filenumber = my_filename[6:10]\n",
        "    for x in range(4):\n",
        "      if output_dict['detection_scores'][x] > 0.5:\n",
        "        myString = my_filenumber + ',' + str(output_dict['detection_scores'][x]) + \",\" + str(output_dict['detection_boxes'][x][0]) + \",\" + str(output_dict['detection_boxes'][x][1]) + \",\" + str(output_dict['detection_boxes'][x][2]) + \",\" + str(output_dict['detection_boxes'][x][3])\n",
        "        print(myString)\n",
        "        with open('output.csv', 'a') as output_file:\n",
        "          output_file.write(myString + '\\n')\n",
        "        \n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        min_score_thresh=.2,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    #plt.figure(figsize=IMAGE_SIZE)\n",
        "    #plt.imshow(image_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBgn9bq-ggI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKkGgIRWiWIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "files.download('output.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}